{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5ojf5aO4R6zVDvM5cY/tf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-with-Student-Papers/blob/main/notebooks/Associate_Student_Essays_%26_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload Files and Add to Dataframe"
      ],
      "metadata": {
        "id": "37V_sOejWvjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gac-bKgMWhOH"
      },
      "outputs": [],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selet all files to upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "_yj_63KxW0Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add files into dataframe\n",
        "import pandas as pd\n",
        "\n",
        "essays = pd.DataFrame.from_dict(uploaded, orient='index')\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "1rdACrLiXNWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset index and add column names to make wrangling easier\n",
        "essays = essays.reset_index()\n",
        "essays.columns = [\"ID\", \"Text\"]\n",
        "essays"
      ],
      "metadata": {
        "id": "3Jn5vTTpXXWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean Texts"
      ],
      "metadata": {
        "id": "zX1jCFC6Z2z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove encoding characters from Text column (b'\\xef\\xbb\\xbf)\n",
        "essays['Text'] = essays['Text'].apply(lambda x: x.decode('utf-8'))\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "t93l5mz2Xdp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove identifying information from ID\n",
        "#Remove any occurences of \"LATE_\" from dataset (otherwise will skew ID cleaning)\n",
        "essays['ID'] = essays['ID'].str.replace(r'LATE_', '', regex=True) \n",
        "\n",
        "#Split book on first underscore (_) in ID, keep only text in between first and second underscore (ID number)\n",
        "start = essays[\"ID\"].str.split(\"_\", expand = True)\n",
        "essays['ID'] = start[1]\n",
        "essays['ID'] = essays['ID'].astype(int)\n",
        "essays"
      ],
      "metadata": {
        "id": "NdmxgHVwYuH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove newline characters\n",
        "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\r', ' ', regex=True) \n",
        "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\n', ' ', regex=True) \n",
        "essays"
      ],
      "metadata": {
        "id": "I0eGyLDCXn4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove headers containing student name, instructor name, course name and date\n",
        "#Split text on 2022 (will likely be last value in headers) and add all contents before to new column\n",
        "headers = essays[\"Text\"].str.split(\"22\", 1, expand = True)\n",
        "essays['Header'] = headers[0]\n",
        "print(essays['Header'])\n",
        "\n",
        "#Add 2022 back to header column\n",
        "essays['Header'] = essays['Header'] + '22'\n",
        "essays['Header'][0]"
      ],
      "metadata": {
        "id": "TtaGs_-lbXGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove any occurences of the header from the rest of the text in each cell (should be at top of each essay in portfolio)\n",
        "essays['Text_NoHeaders'] = essays.apply(lambda row : row['Text'].replace(str(row['Header']), ''), axis=1)\n",
        "essays['Text_NoHeaders'] "
      ],
      "metadata": {
        "id": "APU82K7Gc86W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove old text and header columns from dataframe \n",
        "essays = essays.drop(columns=['Text', 'Header'])\n",
        "essays"
      ],
      "metadata": {
        "id": "mKv7R8Vreuuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This isn't perfect -- headers are not standardized across all papers, sometimes students end with prof name or other info, some student names still visible if referenced in papers themselves. "
      ],
      "metadata": {
        "id": "UrxyT0OzJMey"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Add Grades and Additional Metadata"
      ],
      "metadata": {
        "id": "k_G2_G9tjEBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Selet csv file to upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "5Zr4qZV0jUJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataframe for all metadata and inspect\n",
        "import glob \n",
        "\n",
        "#Link to path where files are stored in drive\n",
        "local_path = r'/content'\n",
        "\n",
        "#Create variable to store all csvs in path\n",
        "filenames = glob.glob(local_path + \"/*.csv\")\n",
        "\n",
        "#Create df list for all csvs\n",
        "dfs = [pd.read_csv(filename) for filename in filenames]\n",
        "\n",
        "# Concatenate all data into one DataFrame\n",
        "metadata = pd.concat(dfs, ignore_index=True)\n",
        "\n",
        "#Change data to string (for further cleaning)\n",
        "metadata.astype(str)\n",
        "\n",
        "metadata"
      ],
      "metadata": {
        "id": "vfaS15UXJzIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop header rows(Points Possible) and test student rows (Student, Test)\n",
        "metadata = metadata[metadata['Student'].str.contains('Points Possible|Student, Test')==False]\n",
        "metadata"
      ],
      "metadata": {
        "id": "xJjrT1GDMEvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get all column names\n",
        "for col in metadata.columns:\n",
        "    print(col)\n",
        "\n",
        "#Choose which rows to keep (ID, section and final portfolios with #s after chosen here)\n",
        "metadata = metadata[['ID', 'Section', \"Final Portfolio (1689777)\", \"Final Portfolio (1676963)\"]]\n",
        "metadata"
      ],
      "metadata": {
        "id": "3nf-IxN9MGV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Replace all NaN values with 0 \n",
        "import numpy as np\n",
        "metadata = metadata.replace(np.nan, 0)"
      ],
      "metadata": {
        "id": "K8MSpnt_RNTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create new final portfolio column with all values\n",
        "#Not sure how this will work with more than two dataframes\n",
        "metadata['Portfolio Score'] = metadata['Final Portfolio (1689777)'] + metadata['Final Portfolio (1676963)']\n",
        "metadata"
      ],
      "metadata": {
        "id": "hFRs22JZjtA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop grade columns for individual classes\n",
        "clean_metadata = metadata[['ID', 'Section', \"Portfolio Score\"]]\n",
        "clean_metadata"
      ],
      "metadata": {
        "id": "wgUp5vA-QTkv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop decimal from ID (inconsistent with ID in essay dataframe)\n",
        "clean_metadata['ID'] = clean_metadata['ID'].astype(int)\n",
        "\n",
        "#Check cleaned DF one more time\n",
        "clean_metadata"
      ],
      "metadata": {
        "id": "IUcrmbcjPeGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Essays and Metadata"
      ],
      "metadata": {
        "id": "hKmEZ7-STghs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge metadata and cleaned essays into new dataframe\n",
        "#Will only keep rows where both essay and metadata are present\n",
        "new_df = clean_metadata.merge(essays,on='ID')\n",
        "new_df"
      ],
      "metadata": {
        "id": "LbXqLKIwnTLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save new df to tsv\n",
        "new_df.to_csv('test_submissions.tsv') \n",
        "files.download('test_submissions.tsv')"
      ],
      "metadata": {
        "id": "aIu4r9SwTr6U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}