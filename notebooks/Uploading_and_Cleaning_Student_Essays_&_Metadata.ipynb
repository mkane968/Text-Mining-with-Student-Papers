{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Uploading and Cleaning Student Essays & Metadata.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMHQM7WSn+02TV4/PbpWKPq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mkane968/Text-Mining-with-Student-Papers/blob/main/Uploading_and_Cleaning_Student_Essays_%26_Metadata.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Upload Files and Add to Dataframe"
      ],
      "metadata": {
        "id": "37V_sOejWvjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gac-bKgMWhOH"
      },
      "outputs": [],
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Selet all files to upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "_yj_63KxW0Nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add files into dataframe\n",
        "import pandas as pd\n",
        "\n",
        "essays = pd.DataFrame.from_dict(uploaded, orient='index')\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "1rdACrLiXNWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reset index and add column names to make wrangling easier\n",
        "essays = essays.reset_index()\n",
        "essays.columns = [\"ID\", \"Text\"]\n",
        "essays"
      ],
      "metadata": {
        "id": "3Jn5vTTpXXWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Clean Texts"
      ],
      "metadata": {
        "id": "zX1jCFC6Z2z8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove encoding characters from Text column (b'\\xef\\xbb\\xbf)\n",
        "essays['Text'] = essays['Text'].apply(lambda x: x.decode('utf-8'))\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "t93l5mz2Xdp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove identifying information from ID\n",
        "#Remove any occurences of \"LATE_\" from dataset (otherwise will skew ID cleaning)\n",
        "essays['ID'] = essays['ID'].str.replace(r'LATE_', '', regex=True) \n",
        "\n",
        "#Split book on first underscore (_) in ID, keep only text in between first and second underscore (ID number)\n",
        "start = essays[\"ID\"].str.split(\"_\", expand = True)\n",
        "essays['ID'] = start[1]\n",
        "essays['ID'] = essays['ID'].astype(int)\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "NdmxgHVwYuH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove newline characters\n",
        "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\r', ' ', regex=True) \n",
        "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\n', ' ', regex=True) \n",
        "essays"
      ],
      "metadata": {
        "id": "I0eGyLDCXn4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove headers containing student name, instructor name, course name and date\n",
        "#Split text on 2022 (will likely be last value in headers) and add all contents before to new column\n",
        "headers = essays[\"Text\"].str.split(\"2022\", 1, expand = True)\n",
        "essays['Header'] = headers[0]\n",
        "print(essays['Header'])\n",
        "\n",
        "#Add 2022 back to header column\n",
        "essays['Header'] = essays['Header'] + '2022'\n",
        "essays['Header'][0]"
      ],
      "metadata": {
        "id": "TtaGs_-lbXGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove any occurences of the header from the rest of the text in each cell (should be at top of each essay in portfolio)\n",
        "essays['Text_NoHeaders'] = essays.apply(lambda row : row['Text'].replace(str(row['Header']), ''), axis=1)\n",
        "essays['Text_NoHeaders'] "
      ],
      "metadata": {
        "id": "APU82K7Gc86W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Remove old text and header columns from dataframe \n",
        "essays = essays.drop(columns=['Text', 'Header'])\n",
        "essays.head()"
      ],
      "metadata": {
        "id": "mKv7R8Vreuuu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Add Grades and Additional Metadata"
      ],
      "metadata": {
        "id": "k_G2_G9tjEBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Selet csv file to upload\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "id": "5Zr4qZV0jUJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create dataframe for metadata\n",
        "metadata = pd.read_csv('2022-08-30T1337_Grades-LA-ENG-0802-711-10742-202220.csv')\n",
        "metadata"
      ],
      "metadata": {
        "id": "Qu4ZM2_7jEP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Clean up metadata to prepare for merge\n",
        "#Rename final portfolio column for clarity \n",
        "metadata = metadata.rename(columns={\"Final Portfolio (1689777)\": \"Final Portfolio\"})\n",
        "\n",
        "#Choose which rows to keep (ID, section and final portfolio chosen here)\n",
        "metadata = metadata[['ID', 'Section', \"Final Portfolio\"]]\n",
        "\n",
        "#Drop first row (header row)-MAKE SURE TO ONLY RUN THIS ONCE!!\n",
        "cleaned_metadata = metadata.iloc[1: , :]\n",
        "\n",
        "#Drop decimal from ID (inconsistent with ID in essay dataframe)\n",
        "cleaned_metadata['ID'] = cleaned_metadata['ID'].astype(int)\n",
        "\n",
        "#Check cleaned DF\n",
        "cleaned_metadata"
      ],
      "metadata": {
        "id": "hFRs22JZjtA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Merge metadata and cleaned essays into new dataframe\n",
        "#Will only keep rows where both essay and metadata are present\n",
        "new_df = cleaned_metadata.merge(essays,on='ID')\n",
        "new_df"
      ],
      "metadata": {
        "id": "LbXqLKIwnTLS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
