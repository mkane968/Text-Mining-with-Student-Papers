{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Mining Student Papers: A Computational Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install os and glob\n",
    "import glob \n",
    "import os\n",
    "\n",
    "#Install pandas\n",
    "import pandas as pd\n",
    "\n",
    "#Install numpy\n",
    "import numpy as np\n",
    "\n",
    "#Imports the Natural Language Toolkit, which is necessary to install NLTK packages and libraries\n",
    "#!pip install nltk\n",
    "import nltk\n",
    "\n",
    "#Installs libraries and packages to tokenize text\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from  nltk.text import ConcordanceIndex\n",
    "\n",
    "#Installs libraries and packages to clean text\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "#Import matplotlib for visualizations\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "#Imports spaCy itself, necessary to use features \n",
    "#!pip install spaCy\n",
    "import spacy\n",
    "#Load the natural language processing pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "#Load spaCy visualizer\n",
    "from spacy import displacy\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "import re  # For preprocessing\n",
    "from time import time  # To time our operations\n",
    "from collections import defaultdict  # For word frequency\n",
    "import logging  # Setting up the loggings to monitor gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Import Student Essays and Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Student Essays and Add to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"/Users/megankane/Desktop/Texts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Append all txt files to pandas dataframe\n",
    "filenames = []\n",
    "data = []\n",
    "files = [f for f in os.listdir(path) if os.path.isfile(f)]\n",
    "for f in files:\n",
    "    if f.endswith('.txt'):\n",
    "        with open (f, \"rb\") as myfile:\n",
    "            filenames.append(myfile.name)\n",
    "            data.append(myfile.read())\n",
    "d = {'ID':filenames,'Text':data}\n",
    "        \n",
    "essays = pd.DataFrame(d)\n",
    "essays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove encoding characters from Text column (b'\\xef\\xbb\\xbf)\n",
    "essays['Text'] = essays['Text'].apply(lambda x: x.decode('utf-8', errors='ignore'))\n",
    "essays['Text'] = essays['Text'].astype(str)\n",
    "\n",
    "#Remove newline characters and put in new column (will need to split paragraphs later)\n",
    "essays['Text_Newlines'] = essays['Text']\n",
    "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\r', ' ', regex=True) \n",
    "essays['Text'] = essays['Text'].str.replace(r'\\s+|\\\\n', ' ', regex=True) \n",
    "essays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove identifying information from ID\n",
    "#Remove any occurences of \"LATE_\" from dataset (otherwise will skew ID cleaning)\n",
    "essays['ID'] = essays['ID'].str.replace(r'LATE_', '', regex=True) \n",
    "\n",
    "#Split book on first underscore (_) in ID, keep only text in between first and second underscore (ID number)\n",
    "start = essays[\"ID\"].str.split(\"_\", expand = True)\n",
    "essays['ID'] = start[1]\n",
    "essays['ID'] = essays['ID'].astype(int)\n",
    "essays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import grades and additional metadata to second dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/megankane/Desktop/CSVs'# use your path\n",
    "\n",
    "#Upload csvs with essay metadata\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "metadata = pd.concat((pd.read_csv(f) for f in all_files), ignore_index=True)\n",
    "\n",
    "#Drop header rows(Points Possible) and test student rows (Student, Test)\n",
    "metadata = metadata[metadata['Student'].str.contains('Points Possible|Student, Test')==False]\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep only relevant metadata (ID, Section, Final Portfolio Scores)\n",
    "clean_metadata = metadata[['ID'] + ['Section'] + list(metadata.loc[:, metadata.columns.str.startswith('Final Portfolio (')])]\n",
    "\n",
    "\n",
    "#Change columns to float as needed (check with df.dtypes())\n",
    "clean_metadata[\"Final Portfolio (1Score)\"] = pd.to_numeric(clean_metadata[\"Final Portfolio (1Score)\"], downcast=\"float\")\n",
    "clean_metadata[\"Final Portfolio (Score)\"] = pd.to_numeric(clean_metadata[\"Final Portfolio (Score)\"], downcast=\"float\")\n",
    "#Want other metadata? Check the columns\n",
    "#Get all column names \n",
    "#for col in metadata.columns:\n",
    "   # print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace all NaN values with 0 \n",
    "clean_metadata = clean_metadata.replace(np.nan, 0)\n",
    "clean_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new final portfolio column with all values\n",
    "#Add values of each column together; values except correct grade will be zero\n",
    "score_counts = clean_metadata.columns[2:]\n",
    "clean_metadata['Portfolio_Score'] = clean_metadata[score_counts].sum(axis=1)\n",
    "clean_metadata['Portfolio_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop grade columns for individual classes\n",
    "clean_metadata = clean_metadata[['ID', 'Section', \"Portfolio_Score\"]]\n",
    "\n",
    "#Round scores to nearest integer\n",
    "clean_metadata.Portfolio_Score = clean_metadata.Portfolio_Score.round()\n",
    "clean_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop decimal from ID (inconsistent with ID in essay dataframe)\n",
    "clean_metadata['ID'] = clean_metadata['ID'].astype(float)\n",
    "clean_metadata['ID'] = clean_metadata['ID'].astype(int)\n",
    "\n",
    "\n",
    "#Check cleaned DF one more time\n",
    "clean_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge essays and grade metadata into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge metadata and cleaned essays into new dataframe\n",
    "#Will only keep rows where both essay and metadata are present\n",
    "essays_grades_master = clean_metadata.merge(essays,on='ID')\n",
    "\n",
    "#Print dataframe\n",
    "essays_grades_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort dataframe by grades\n",
    "essays_grades_master.sort_values(by=['Portfolio_Score'], inplace = True)\n",
    "essays_grades_master.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Clean Data\n",
    "\n",
    "### Basic Cleaning with NLTK\n",
    "Lowercasing, Punctuation Removal, and Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rename dataframe\n",
    "clean_essay_grades_df = essays_grades_master\n",
    "clean_essay_grades_df.rename(columns = {\"Text_NoHeaders\": \"Text\"}, inplace = True)\n",
    "\n",
    "#Lowercase all words\n",
    "clean_essay_grades_df['Lower_Text'] = clean_essay_grades_df['Text'].str.lower()\n",
    "\n",
    "#Remove punctuation and replace with no space (except periods and hyphens)\n",
    "clean_essay_grades_df['NoPunct_Text'] = clean_essay_grades_df['Lower_Text'].str.replace(r'[^\\w\\-\\.\\'\\s]+', '', regex = True)\n",
    "\n",
    "#Remove periods and replace with space (to prevent incorrect compounds)\n",
    "clean_essay_grades_df['NoPunct_Text'] = clean_essay_grades_df['NoPunct_Text'].str.replace(r'[^\\w\\-\\'\\s]+', ' ', regex = True)\n",
    "\n",
    "#Remove stopwords\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "clean_essay_grades_df['NoStops_Text'] = clean_essay_grades_df['Text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "#Check output\n",
    "clean_essay_grades_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Text Enrichment\n",
    "\n",
    "Lemmatization, Part-of-Speech Tagging, and Named Entity Recognition with SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get lemmas\n",
    "lemma_list = []\n",
    "\n",
    "# Disable Dependency Parser, and NER since all we want is lemmatizer \n",
    "with nlp.disable_pipes('parser', 'ner'):\n",
    "  #Iterate through each doc object and getlemma, append lemma to list\n",
    "  for doc in nlp.pipe(clean_essay_grades_df.NoPunct_Text.astype('unicode').values, batch_size=100):\n",
    "    word_list = []\n",
    "    for token in doc:\n",
    "        word_list.append(token.lemma_)\n",
    "        \n",
    "    lemma_list.append(word_list)\n",
    "\n",
    "#Put lemmas in a new column in dataframe\n",
    "clean_essay_grades_df['Lemma_Text'] = lemma_list\n",
    "clean_essay_grades_df['Lemma_Text'] = [' '.join(map(str, l)) for l in clean_essay_grades_df['Lemma_Text']]\n",
    "\n",
    "#Check lemmas\n",
    "clean_essay_grades_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get part of speech tags\n",
    "pos_list = []\n",
    "\n",
    "# Disable Dependency Parser, and NER since all we want is POS \n",
    "with nlp.disable_pipes('parser', 'ner'):\n",
    "  #Iterate through each doc object and tag POS, append POS to list\n",
    "  for doc in nlp.pipe(clean_essay_grades_df.NoPunct_Text.astype('unicode').values, batch_size=100):\n",
    "    word_list = []\n",
    "    for token in doc:\n",
    "        word_list.append(token.pos_)\n",
    "        \n",
    "    pos_list.append(word_list)\n",
    "\n",
    "#Put POS in a new column in dataframe\n",
    "clean_essay_grades_df['POS_Text'] = pos_list\n",
    "clean_essay_grades_df['POS_Text'] = [' '.join(map(str, l)) for l in clean_essay_grades_df['POS_Text']]\n",
    "\n",
    "#Check pos tags\n",
    "clean_essay_grades_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get named entities\n",
    "ent_list = []\n",
    "\n",
    "with nlp.disable_pipes('tagger', 'parser'):\n",
    "    for doc in nlp.pipe(clean_essay_grades_df.NoPunct_Text.astype('unicode').values, batch_size=100):\n",
    "        ent_list.append(doc.ents)\n",
    "\n",
    "#Put NEs in a new column in dataframe\n",
    "clean_essay_grades_df['NER_Text'] = ent_list\n",
    "clean_essay_grades_df['NER_Text'] = [' '.join(map(str, l)) for l in clean_essay_grades_df['NER_Text']]\n",
    "\n",
    "#Check named entities\n",
    "clean_essay_grades_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Paragraph Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only need one newlines version here\n",
    "paragraphs_df = clean_essay_grades_df[['Portfolio_Score','ID', 'Text_Newlines']].copy()\n",
    "\n",
    "#Add ID and score in one column\n",
    "paragraphs_df['Score_ID'] = 'Score: ' + paragraphs_df['Portfolio_Score'].astype(str) + ', ID: ' + paragraphs_df['ID'].astype(str)\n",
    "\n",
    "#Check new df\n",
    "paragraphs_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count number of paragraphs in each text\n",
    "paragraph_counts = paragraphs_df['Text_Newlines'].str.count(r'\\n')\n",
    "paragraph_counts\n",
    "\n",
    "#Append paragraphs counts to dataframe\n",
    "paragraphs_df[\"Paragraph_Counts\"] = paragraph_counts\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make new cell each time new paragraph starts \n",
    "new = paragraphs_df[\"Text_Newlines\"].str.split(r'\\n', expand = True).set_index(paragraphs_df['Score_ID'])\n",
    "\n",
    "#Flatten dataframe so each chapter is on own row, designated by book and chapter \n",
    "paragraphs_df = new.stack().reset_index()\n",
    "paragraphs_df.columns = [\"Score_ID\", \"Paragraph\", \"Text\"]\n",
    "\n",
    "#Split score and ID back to own columns\n",
    "paragraphs_df[['Score','ID']] = paragraphs_df.Score_ID.str.split(\", \",expand=True)\n",
    "paragraphs_df['Score'] = paragraphs_df['Score'].map(lambda x: x.lstrip('Score: '))\n",
    "paragraphs_df['ID'] = paragraphs_df['ID'].map(lambda x: x.lstrip('ID: '))\n",
    "paragraphs_df['ID_Paragraph'] = paragraphs_df['ID'].astype(str) + '_' + paragraphs_df['Paragraph'].astype(str)\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clean paragraphs\n",
    "##Filter out paragraphs with 5 or less words (headers)\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.split().str.len().lt(10)]\n",
    "\n",
    "## Filter out paragraphs containing \"http://\", \"doi:\" , \"https://\" and \"://www\" (Works Cited citations)\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"http://\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"https://\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"://www\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"www.\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\".com/\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"Vol.\")]\n",
    "\n",
    "paragraphs_df = paragraphs_df[~paragraphs_df['Text'].str.contains(\"doi:\")]\n",
    "\n",
    "paragraphs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify Keywords in Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome 1: Extracting Rhetorical Analysis Terms and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Set up new dataframe for keyword frequency counts\n",
    "rhetorical_keywords_paragraphs_df = paragraphs_df.copy()\n",
    "\n",
    "#Count number of occurences of rhetorical terms in each paper\n",
    "pathos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('pathos')\n",
    "ethos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('ethos')\n",
    "logos_counts = rhetorical_keywords_paragraphs_df['Text'].str.count('logos')\n",
    "\n",
    "#Append each count to the dataframe\n",
    "rhetorical_keywords_paragraphs_df['Pathos_Counts'] = pathos_counts\n",
    "rhetorical_keywords_paragraphs_df[\"Ethos_Counts\"] = ethos_counts\n",
    "rhetorical_keywords_paragraphs_df[\"Logos_Counts\"] = logos_counts\n",
    "\n",
    "#Get summ of all term usages\n",
    "rhetorical_terms = ['Pathos_Counts', 'Ethos_Counts', 'Logos_Counts']\n",
    "rhetorical_keywords_paragraphs_df['Sum_Terms'] = rhetorical_keywords_paragraphs_df[rhetorical_terms].sum(axis=1)\n",
    "\n",
    "#Split score and ID back to own columns\n",
    "rhetorical_keywords_paragraphs_df[['Score','ID']] = rhetorical_keywords_paragraphs_df.Score_ID.str.split(\", \",expand=True)\n",
    "rhetorical_keywords_paragraphs_df['Score'] = rhetorical_keywords_paragraphs_df['Score'].map(lambda x: x.lstrip('Score: '))\n",
    "rhetorical_keywords_paragraphs_df['ID'] = rhetorical_keywords_paragraphs_df['Score'].map(lambda x: x.lstrip('ID: '))\n",
    "\n",
    "rhetorical_keywords_paragraphs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows with no rhetorical terms\n",
    "rhetorical_keywords_paragraphs_df_no_blanks = rhetorical_keywords_paragraphs_df[rhetorical_keywords_paragraphs_df.Sum_Terms > 0]\n",
    "rhetorical_keywords_paragraphs_df_no_blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome 2: Extracting Citation Practices and Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get any text inside parentheticals and count of parentheticals and append to dataframe\n",
    "#https://stackoverflow.com/questions/24696715/regex-for-match-parentheses-in-python\n",
    "parentheticals = r'(?<=\\().*?(?=\\))'\n",
    "\n",
    "#Add new list for parenthetical citations\n",
    "parenthetical_matches = []\n",
    "parenthetical_counts = []\n",
    "\n",
    "#Find all occurences of parenthetical citations in each paragraph of each text\n",
    "citation_df = paragraphs_df.copy()\n",
    "for text in citation_df['Text']:\n",
    "  matches = re.findall(parentheticals, text)\n",
    "  parenthetical_matches.append(matches)\n",
    "  parenthetical_counts.append(len(matches))\n",
    "\n",
    "#Make new column counting all appearances of parentheticals\n",
    "citation_df[\"Parentheticals\"] = parenthetical_matches\n",
    "citation_df['Parenthetical_Counts'] = parenthetical_counts\n",
    "\n",
    "citation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove all rows with no parenthetical terms\n",
    "citation_df_no_blanks = citation_df[citation_df.Parenthetical_Counts > 0]\n",
    "citation_df_no_blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Analyze Keywords in Context\n",
    "This section uses frequency plots and regression analysis to determine whether rhetorical analysis term usage and/or citation practice usage are good indicators of score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rhetorical Terms Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need the metadata and text with newlines here; we'll also take the nostops text for further count analysis\n",
    "rhetorical_keywords_df_full_texts = clean_essay_grades_df[['ID', 'Section', 'Portfolio_Score', 'Text_Newlines', 'NoStops_Text']].copy()\n",
    "\n",
    "#Add ID and score in one column\n",
    "rhetorical_keywords_df_full_texts['Score_ID'] = 'Score: ' + rhetorical_keywords_df_full_texts['Portfolio_Score'].astype(str) + ', ID:' + rhetorical_keywords_df_full_texts['ID'].astype(str)\n",
    "\n",
    "#Check new df\n",
    "rhetorical_keywords_df_full_texts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count usage of each term in each essay\n",
    "pathos_counts = rhetorical_keywords_df_full_texts['NoStops_Text'].str.count('pathos')\n",
    "ethos_counts = rhetorical_keywords_df_full_texts['NoStops_Text'].str.count('ethos')\n",
    "logos_counts = rhetorical_keywords_df_full_texts['NoStops_Text'].str.count('logos')\n",
    "\n",
    "#Append each count to the dataframe\n",
    "rhetorical_keywords_df_full_texts['Pathos_Counts'] = pathos_counts\n",
    "rhetorical_keywords_df_full_texts[\"Ethos_Counts\"] = ethos_counts\n",
    "rhetorical_keywords_df_full_texts[\"Logos_Counts\"] = logos_counts\n",
    "\n",
    "#Get summ of all term usages\n",
    "rhetorical_terms = ['Pathos_Counts', 'Ethos_Counts', 'Logos_Counts']\n",
    "rhetorical_keywords_df_full_texts['Sum_Terms'] = rhetorical_keywords_df_full_texts[rhetorical_terms].sum(axis=1)\n",
    "\n",
    "rhetorical_keywords_df_full_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart number of times each term was used in each essay \n",
    "#Create bar graph\n",
    "#https://plotly.com/python/bar-charts/\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Pathos Counts', x=rhetorical_keywords_df_full_texts[\"Score_ID\"], y=rhetorical_keywords_df_full_texts[\"Pathos_Counts\"]),\n",
    "    go.Bar(name='Ethos Counts', x=rhetorical_keywords_df_full_texts[\"Score_ID\"], y=rhetorical_keywords_df_full_texts[\"Ethos_Counts\"]),\n",
    "    go.Bar(name='Logos Counts', x=rhetorical_keywords_df_full_texts[\"Score_ID\"], y=rhetorical_keywords_df_full_texts[\"Logos_Counts\"]),\n",
    "    go.Bar(name='All Term Counts', x=rhetorical_keywords_df_full_texts[\"Score_ID\"], y=rhetorical_keywords_df_full_texts[\"Sum_Terms\"]),\n",
    "\n",
    "])\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Counts of Each Rhetorical Term in Each Essay')\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if amount of all term usage is indicative of grade\n",
    "#Based on results, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
    "\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(rhetorical_keywords_df_full_texts['Portfolio_Score'])\n",
    "y = np.array(rhetorical_keywords_df_full_texts['Sum_Terms'])\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data', color = 'g')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.xlabel(\"Paper Score\")\n",
    "plt.ylabel(\"Rhetorical Term Counts\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"R-squared for Rhetorical Terms: {result.rvalue**2:}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if amount of usages of pathos is indicative of grade\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(rhetorical_keywords_df_full_texts['Portfolio_Score'])\n",
    "y = np.array(rhetorical_keywords_df_full_texts['Pathos_Counts'])\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "print(f\"R-squared for Pathos Terms: {result.rvalue**2:}\")\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Check if amount of usages of logos is indicative of grade\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(rhetorical_keywords_df_full_texts['Portfolio_Score'])\n",
    "y = np.array(rhetorical_keywords_df_full_texts['Logos_Counts'])\n",
    "\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "print(f\"R-squared for Logos Terms: {result.rvalue**2:}\")\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#Check if amount of usages of ethos is indicative of grade\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(rhetorical_keywords_df_full_texts['Portfolio_Score'])\n",
    "y = np.array(rhetorical_keywords_df_full_texts['Ethos_Counts'])\n",
    "\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "print(f\"R-squared for Ethos Terms: {result.rvalue**2:}\")\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot # paragraphs in which terms were used vs. essay grade\n",
    "##In other words, do more successful writers use terms in multiple paragrpahs (indicating more coherence)?\n",
    "\n",
    "#Count number of paragraphs where terms used and append to new dataframe\n",
    "new_Series = rhetorical_keywords_paragraphs_df_no_blanks['Score_ID'].value_counts(ascending=True)\n",
    "df3 = pd.DataFrame(new_Series).reset_index()\n",
    "df3\n",
    "\n",
    "df3.rename(columns={\"index\": \"Score_ID\", \"Score_ID\": \"Paragraph_Counts\"}, errors=\"raise\", inplace=True)\n",
    "df3[['ID','Score']] = df3.Score_ID.str.split(\", \",expand=True)\n",
    "\n",
    "df3\n",
    "\n",
    "#Plot paragraph counts per paper\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Paragraph Counts', x=df3[\"Score_ID\"], y=df3[\"Paragraph_Counts\"]),\n",
    "\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Number of Paragraphs Where Rhetorical Terms Were Used')\n",
    "fig.update_layout(barmode='stack', xaxis={'categoryorder':'category ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new df for paragraph counts\n",
    "df3[['Score','ID']] = df3.Score_ID.str.split(\", \",expand=True)\n",
    "df3['Score'] = df3['Score'].map(lambda x: x.lstrip('Score: '))\n",
    "df3 = df3[['Score','Paragraph_Counts']].copy()\n",
    "df3 = df3.apply(pd.to_numeric)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if amount of paragraph term usage is indicative of grade\n",
    "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
    "from scipy import stats\n",
    "\n",
    "#Check if amount of usages of all terms per paragraph is indicative of grade\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "\n",
    "\n",
    "x = np.array(df3['Score'])\n",
    "y = np.array(df3['Paragraph_Counts'])\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "print(f\"R-squared for Terms Per Paragraph: {result.rvalue**2:}\")\n",
    "\n",
    "plt.plot(x, y, 's', label='original data')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'y', label='fitted line')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Citation Practice Regression Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using FULL TEXTS Get any text inside parentheticals and count of parentheticals and append to dataframe\n",
    "#https://stackoverflow.com/questions/24696715/regex-for-match-parentheses-in-python\n",
    "parentheticals = r'(?<=\\().*?(?=\\))'\n",
    "\n",
    "parenthetical_matches = []\n",
    "parenthetical_counts = []\n",
    "\n",
    "citation_df_full_texts = clean_essay_grades_df[['ID', 'Section', 'Portfolio_Score','Text']].copy()\n",
    "for text in citation_df_full_texts['Text']:\n",
    "  matches = re.findall(parentheticals, text)\n",
    "  parenthetical_matches.append(matches)\n",
    "  parenthetical_counts.append(len(matches))\n",
    "\n",
    "citation_df_full_texts[\"Parentheticals\"] = parenthetical_matches\n",
    "citation_df_full_texts['Parenthetical_Counts'] = parenthetical_counts\n",
    "citation_df_full_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add ID and score in one column\n",
    "citation_df_full_texts['Score_ID'] = 'Score: ' + citation_df_full_texts['Portfolio_Score'].astype(str) + ', ID:' + citation_df_full_texts['ID'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart number of times parentheticals were used in each essay \n",
    "#Create bar graph\n",
    "#https://plotly.com/python/bar-charts/\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Parenthetical_Tags', x=citation_df_full_texts[\"Score_ID\"], y=citation_df_full_texts[\"Parenthetical_Counts\"])\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Counts of Parentheticals Used in Each Essay')\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression: Parentheticals vs. Grade\n",
    "\n",
    "#Check if amount of all term usage is indicative of grade\n",
    "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(citation_df_full_texts['Portfolio_Score'])\n",
    "y = np.array(citation_df_full_texts['Parenthetical_Counts'])\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "\n",
    "plt.plot(x, y, 's', label='Student Essay Data', color = 'y')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.xlabel(\"Paper Score\")\n",
    "plt.ylabel(\"Parenthetical Citation Counts\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"R-squared for Parenthetical Citations: {result.rvalue**2:}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot # paragraphs in which terms were used vs. essay grade\n",
    "##In other words, do more successful writers use terms in multiple paragrpahs (indicating more coherence)?\n",
    "\n",
    "#Count number of paragraphs where terms used and append to new dataframe\n",
    "new_Series = citation_df['Score_ID'].value_counts(ascending=True)\n",
    "df3 = pd.DataFrame(new_Series).reset_index()\n",
    "df3\n",
    "\n",
    "df3.rename(columns={\"index\": \"Score_ID\", \"Score_ID\": \"Paragraph_Counts\"}, errors=\"raise\", inplace=True)\n",
    "df3[['ID','Score']] = df3.Score_ID.str.split(\", \",expand=True)\n",
    "\n",
    "df3\n",
    "\n",
    "#Plot paragraph counts per paper\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Paragraph Counts', x=df3[\"Score_ID\"], y=df3[\"Paragraph_Counts\"]),\n",
    "\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Number of Paragraphs Where Citation Terms Were Used')\n",
    "fig.update_layout(barmode='stack', xaxis={'categoryorder':'category ascending'})\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3[['Score','ID']] = df3.Score_ID.str.split(\", \",expand=True)\n",
    "df3['Score'] = df3['Score'].map(lambda x: x.lstrip('Score: '))\n",
    "df3 = df3[['Score','Paragraph_Counts']].copy()\n",
    "df3 = df3.apply(pd.to_numeric)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if amount of paragraph term usage is indicative of grade\n",
    "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
    "from scipy import stats\n",
    "\n",
    "#Check if amount of usages of all terms per paragraph is indicative of grade\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "\n",
    "\n",
    "x = np.array(df3['Score'])\n",
    "y = np.array(df3['Paragraph_Counts'])\n",
    "\n",
    "#Return key values of linear regressionslope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.xlabel(\"Paper Score\")\n",
    "plt.ylabel(\"Paragraph Counts of Parenthetical Citations\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"R-squared for Parenthetical Citations Per Paragraph: {result.rvalue**2:}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis below uses output from the DocuScope Corpus Analysis platform. This platform is freely available for download from Carnegie Melon University:https://www.cmu.edu/dietrich/english/research-and-publications/docuscope.html\n",
    " \n",
    "\n",
    "DocuScope is a dictionary-based tool that \"tags\" words and phrases in texts based on its 50+ categories of rhetorical primers. The tool might tag the words “according to,” and “is proposing that” as evidence that the student is engaging in citation, for example. In aggregate, these counts can indicate to what degree each text in a corpus contains language indicating a particular rhetorical effect. Our interest in this case is the language DocuScope has tagged as indicating \"Citation\" is occuring; this language can be isolated from the CSV generated from the DocuScope tool, and an example can be found on this Github repository. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Get current working directory \n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#Change working directory\n",
    "path = os.chdir(\"/Users/megankane/Desktop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats_df = pd.read_csv('DIMENSION_C_deidentified_texts_citation_clusters.csv')\n",
    "lats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make ID document to merge docuscope lats with\n",
    "ids = clean_essay_grades_df[['ID', 'Portfolio_Score']].copy()\n",
    "ids\n",
    "\n",
    "#Rename filename column to id and merge target and LAT tables based on ID\n",
    "lats_df.rename(columns={\"Filename\": \"ID\"}, inplace=True)\n",
    "lats_df['ID'] = lats_df['ID'].map(lambda x: x.rstrip('.txt'))\n",
    "lats_df['ID'] = lats_df['ID'].astype('float')\n",
    "merged_lat_df = pd.merge(ids, lats_df, on='ID')\n",
    "\n",
    "#Add ID and score in one column\n",
    "merged_lat_df['Score_ID'] = 'Score: ' + merged_lat_df['Portfolio_Score'].astype(str) + ', ID:' + merged_lat_df['ID'].astype(str)\n",
    "merged_lat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart number of times all terms were used in each essay \n",
    "#Create bar graph\n",
    "#https://plotly.com/python/bar-charts/\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='Citations_Tags', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"Citation\"])\n",
    "])\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Counts of All Citation Cluster Terms Used in Each Essay')\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression: Citation vs. Grade\n",
    "\n",
    "#Check if amount of all term usage is indicative of grade\n",
    "#Based on results (r = .08, there is little relationship between amount of rhetorical terms used and grade...at least between A and B range essays)\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "#Create arrays of independent (x) and dependent (y) variables\n",
    "x = np.array(merged_lat_df['Portfolio_Score'])\n",
    "y = np.array(merged_lat_df['Citation'])\n",
    "\n",
    "#Return key values of linear regression\n",
    "slope, intercept, r, p, std_err = stats.linregress(x, y)\n",
    "\n",
    "result = stats.linregress(x, y)\n",
    "\n",
    "\n",
    "plt.plot(x, y, 'o', label='Student Essay Data', color = 'k')\n",
    "plt.plot(x, result.intercept + result.slope*x, 'r', label='Predicted Score')\n",
    "plt.xlabel(\"Paper Score\")\n",
    "plt.ylabel(\"DocuScope Citation Counts\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f\"R-squared for DocuScope Citations: {result.rvalue**2:}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chart number of times each citation dimension was used in each essay \n",
    "#Create bar graph\n",
    "#https://plotly.com/python/bar-charts/\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure(data=[\n",
    "    go.Bar(name='CitationAuthority', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationAuthority\"]),\n",
    "    go.Bar(name='CitationControversy', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationControversy\"]),\n",
    "    go.Bar(name='CitationGeneric', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationGeneric\"]),\n",
    "    go.Bar(name='CitationHedged', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationHedged\"]),\n",
    "    go.Bar(name='CitationNegative', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationNegative\"]),\n",
    "    go.Bar(name='CitationNeutral', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationNeutral\"]),\n",
    "    go.Bar(name='CitationSpeakerLookMood', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"CitationSpeakerLookMood\"]),\n",
    "    go.Bar(name='UncertainCitation', x=merged_lat_df[\"Score_ID\"], y=merged_lat_df[\"UncertainCitation\"]),\n",
    "\n",
    "])\n",
    "\n",
    "\n",
    "# Change the bar mode\n",
    "fig.update_layout(title_text='Counts of Each Rhetorical Term in Each Essay')\n",
    "fig.update_layout(barmode='stack')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
